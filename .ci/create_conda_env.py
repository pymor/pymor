#!/usr/bin/env python3

import itertools
import json
import operator
import os
from contextlib import contextmanager
from functools import reduce
from pathlib import Path
from pprint import pformat
from subprocess import check_output, CalledProcessError
from typing import List, Dict

import jinja2
import logging

import typer

REQUIRED_PLATFORMS = ('osx-64', 'linux-64', 'win-64')
# stars are not actually a glob pattern, but as-is in the conda search output
REQUIRED_PYTHONS = ('3.8.*', '3.9.*')
ANY_PYTHON_VERSION = 'any_python'
NO_PYTHON_VERSION = -1

ENV_TPL = r'''# THIS FILE IS AUTOGENERATED -- DO NOT EDIT #
name: pyMOR-ci
channels:
  - conda-forge
dependencies:
  - anaconda-client
  - conda-build
  - pip
{% for pkg in available %}
  - {{pkg}}
{%- endfor %}

  - pip:
    - -r ../requirements-ci.txt
# THIS FILE IS AUTOGENERATED -- DO NOT EDIT #

'''

BLOCKLIST = tuple()
PYPI_TO_CONDA_PACKAGENAME_MAPPING = {'torch': ['pytorch-cpu'],
                                     'gmsh': ['python-gmsh', 'gmsh']}
NO_ARCH = ['noarch', None]
THIS_DIR = Path(__file__).resolve().parent
LOGFILE = THIS_DIR / 'create_conda_env.log'

logging.basicConfig(filename=LOGFILE, level=logging.DEBUG, filemode='wt')


@contextmanager
def change_to_directory(name):
    """Change current working directory to `name` for the scope of the context."""
    old_cwd = os.getcwd()
    try:
        yield os.chdir(name)
    finally:
        os.chdir(old_cwd)


def _parse_req_file(path) -> List[str]:
    path = Path(path).resolve()
    assert path.exists()
    assert path.is_file()
    pkgs = []
    with change_to_directory(path.parent):
        for line in open(path, 'rt').readlines():
            line = line.strip()
            if line.startswith('-r'):
                pkgs += _parse_req_file(line[line.find('-r ') + 3:])
                continue
            if line.startswith('#'):
                continue
            if ';' in line:
                dropped = line.split(';')[0]
                logging.debug(f'Dropping chained specifier, using {dropped} instead of {line}')
                line = dropped
            name_only = _strip_markers(line)
            if name_only in BLOCKLIST:
                continue
            if name_only in PYPI_TO_CONDA_PACKAGENAME_MAPPING.keys():
                mapped_pkgs = PYPI_TO_CONDA_PACKAGENAME_MAPPING[name_only]
                for mapped_pkg in mapped_pkgs[:-2]:
                    line = line.replace(name_only, mapped_pkg)
                for mapped_pkg in mapped_pkgs[-2:]:
                    # more than 1 replacement means pkg is split into multiple in conda
                    pkgs.append(mapped_pkg)
            pkgs.append(line)
    return pkgs


def _strip_markers(name: str) -> str:
    for m in '!;<>=':
        try:
            i = name.index(m)
            name = name[:i].strip()
        except ValueError:
            continue
    return name


def _search_single(pkg: str, plat: str):
    """Search needs to explicitly say its subdir, else only the host's native is searched"""
    cmd = ['/usr/bin/env', 'conda', 'search', '--channel=conda-forge', '--json', f'{pkg}[subdir={plat}]']
    try:
        output = check_output(cmd)
    except CalledProcessError as e:
        if plat not in NO_ARCH:
            logging.debug(f'Falling back to noarch for {pkg} - {plat}')
            for noarch in NO_ARCH:
                try:
                    return _search_single(pkg, noarch)
                except Exception:
                    continue
            raise RuntimeError(f"noarch search failed for {pkg}") from e
        try:
            err = json.loads(e.output)['error']
            if 'PackagesNotFoundError' in err:
                return None, []
        except Exception as ex:
            raise RuntimeError(f"Failed json load for {pkg} = {plat}") from ex
        raise RuntimeError(f"{pkg} = {plat}: err") from e

    pkg_name = _strip_markers(pkg).lower()
    out = json.loads(output)
    ll = list(itertools.chain.from_iterable((data for name, data in out.items() if name == pkg_name)))
    return plat, list(reversed(ll))


def _extract_conda_py(release: Dict):
    try:
        if release['package_type'] == 'noarch_python':
            return ANY_PYTHON_VERSION
    except KeyError:
        pass
    try:
        if release['arch'] is None and release['platform'] is None:
            return ANY_PYTHON_VERSION
    except KeyError:
        pass
    for pkg in release['depends']:
        if pkg.startswith('python_abi'):
            # format 'python_abi 3.9.* *_cp39'
            return pkg.split(' ')[1]
        if pkg.startswith('python'):
            # format ''python >=3.9,<3.10.0a0''
            l, r = pkg.find('>='), pkg.find(',')
            return pkg[l + 2:r] + '.*'
    return NO_PYTHON_VERSION


def _available_on_required(json_result, required_plats, required_pys):
    required_tuples = list(itertools.product(required_plats, required_pys))
    name = 'PackageNameNotSet'
    for release in json_result:
        name = release['name']

        def _debug(msg):
            logging.debug(f"{name}: {msg}")

        plat = release['subdir']
        if plat not in required_plats and plat not in NO_ARCH:
            _debug(f'{plat} unknown/not needed')
            continue
        py = _extract_conda_py(release)
        _debug(f'{plat} needs {py}')
        if py in required_pys or py == ANY_PYTHON_VERSION:
            covered_pys = [py] if py != ANY_PYTHON_VERSION else required_pys
            covered_plats = [plat] if plat not in NO_ARCH else required_plats
            to_remove = itertools.product(covered_plats, covered_pys)
            for pair in to_remove:
                try:
                    # combinations can be found multiple times
                    required_tuples.remove(pair)
                except ValueError as e:
                    if 'list.remove' in str(e):
                        continue
                    raise RuntimeError(f"processing {plat} - {py} failed for release: {release}") from e
        if len(required_tuples) == 0:
            _debug('all required tuples found')
            return True

    logging.error(f'{name} not available on {required_tuples}:\n{pformat(json_result)}')
    return False


def _search(pkg):
    """If a result is noarch, we can return early"""
    for plat in REQUIRED_PLATFORMS:
        found_plat, json_list = _search_single(pkg, plat)
        yield json_list
        if found_plat in NO_ARCH:
            return


def _process_inputs(input_paths):
    available = []
    wanted = set(reduce(operator.concat, (_parse_req_file(p) for p in input_paths)))
    for pkg in wanted:
        data = reduce(operator.concat, _search(pkg))
        if _available_on_required(json_result=data,
                                  required_plats=REQUIRED_PLATFORMS,
                                  required_pys=REQUIRED_PYTHONS):
            available.append(pkg)
    for a in available:
        wanted.remove(a)
    return sorted(list(available)), sorted(list(wanted))


def main(input_paths: List[Path], output_path: Path = None):
    output_path = output_path or THIS_DIR / 'conda-env.yml'
    available, wanted = _process_inputs(input_paths)
    tpl = jinja2.Template(ENV_TPL)
    with open(output_path, 'wt') as yml:
        yml.write(tpl.render(available=available))
    from rich.console import Console
    from rich.table import Table

    table = Table("available", "wanted", title="Conda search result")
    for el in itertools.zip_longest(available, wanted, fillvalue=''):
        table.add_row(*el)
    console = Console(record=True)
    console.print(table)
    logging.info(console.export_text())
    console.print(f'Details at {LOGFILE}')


if __name__ == '__main__':
    typer.run(main)
