#!/usr/bin/env python3

import itertools
import json
import logging
import operator
import os
from contextlib import contextmanager
from functools import reduce
from pathlib import Path
from pprint import pformat
from subprocess import CalledProcessError, check_output
from typing import Dict, List

import jinja2
import typer

REQUIRED_PLATFORMS = ('osx-64', 'linux-64', 'win-64')
# stars are not actually a glob pattern, but as-is in the conda search output
REQUIRED_PYTHONS = ('3.8.*', '3.10.*')
ANY_PYTHON_VERSION = 'any_python'
NO_PYTHON_VERSION = -1

ENV_TPL = r"""# THIS FILE IS AUTOGENERATED -- DO NOT EDIT #
name: pyMOR-ci
channels:
  - conda-forge
dependencies:
  - anaconda-client
  - conda-build
  - pip
{% for pkg in available %}
  - {{pkg}}
{%- endfor %}
# THIS FILE IS AUTOGENERATED -- DO NOT EDIT #

"""

# AFAICT we _should_ install pytorch-cpu instead of torch, that
# fails to install everywhere, so we're noping out of torch entirely
BLOCKLIST = ('torch', 'sphinx-material')
PYPI_TO_CONDA_PACKAGENAME_MAPPING = {'torch': ['pytorch-cpu'],
                                     'gmsh': ['python-gmsh', 'gmsh']}
NO_ARCH = ['noarch', None]
THIS_DIR = Path(__file__).resolve().parent
LOGFILE = THIS_DIR / 'create_conda_env.log'

logging.basicConfig(filename=LOGFILE, level=logging.DEBUG, filemode='wt')


@contextmanager
def change_to_directory(name):
    """Change current working directory to `name` for the scope of the context."""
    old_cwd = os.getcwd()
    try:
        yield os.chdir(name)
    finally:
        os.chdir(old_cwd)


def _parse_req_file(path) -> List[str]:
    path = Path(path).resolve()
    assert path.exists()
    assert path.is_file()
    pkgs = []
    with change_to_directory(path.parent):
        for line in open(path, 'rt').readlines():
            line = line.strip()
            if line.startswith('-r'):
                pkgs += _parse_req_file(line[line.find('-r ') + 3:])
                continue
            if line.startswith('#'):
                continue
            if ';' in line:
                dropped = line.split(';')[0]
                logging.debug(f'Dropping chained specifier, using {dropped} instead of {line}')
                line = dropped
            name_only = _strip_markers(line)
            if name_only in BLOCKLIST:
                continue
            if name_only in PYPI_TO_CONDA_PACKAGENAME_MAPPING.keys():
                mapped_pkgs = PYPI_TO_CONDA_PACKAGENAME_MAPPING[name_only]
                for mapped_pkg in mapped_pkgs[:-2]:
                    line = line.replace(name_only, mapped_pkg)
                for mapped_pkg in mapped_pkgs[-2:]:
                    # more than 1 replacement means pkg is split into multiple in conda
                    pkgs.append(mapped_pkg)
            pkgs.append(line)
    return pkgs


def _strip_markers(name: str) -> str:
    for m in '!;<>=':
        try:
            i = name.index(m)
            name = name[:i].strip()
        except ValueError:
            continue
    return name


def _search_single(pkg: str, plat: str):
    """Search needs to explicitly say its subdir, else only the host's native is searched."""
    cmd = ['/usr/bin/env', 'conda', 'search', '--channel=conda-forge', '--json', f'{pkg}[subdir={plat}]']
    try:
        output = check_output(cmd)
    except CalledProcessError as e:
        if plat not in NO_ARCH:
            logging.debug(f'Falling back to noarch for {pkg} - {plat}')
            for noarch in NO_ARCH:
                try:
                    return _search_single(pkg, noarch)
                except Exception:
                    continue
            raise RuntimeError(f'noarch search failed for {pkg}') from e
        try:
            err = json.loads(e.output)['error']
            if 'PackagesNotFoundError' in err:
                return None, []
        except Exception as ex:
            raise RuntimeError(f'Failed json load for {pkg} = {plat}') from ex
        raise RuntimeError(f'{pkg} = {plat}: err') from e

    pkg_name = _strip_markers(pkg).lower()
    out = json.loads(output)
    ll = list(itertools.chain.from_iterable((data for name, data in out.items() if name == pkg_name)))
    return plat, list(reversed(ll))


def _extract_conda_py(release: Dict):
    try:
        if release['package_type'] == 'noarch_python':
            return ANY_PYTHON_VERSION
    except KeyError:
        pass
    try:
        if release['arch'] is None and release['platform'] is None:
            return ANY_PYTHON_VERSION
    except KeyError:
        pass
    for pkg in release['depends']:
        if pkg.startswith('python_abi'):
            # format 'python_abi 3.9.* *_cp39'
            return pkg.split(' ')[1]
        if pkg.startswith('python'):
            # format ''python >=3.9,<3.10.0a0''
            l, r = pkg.find('>='), pkg.find(',')
            return pkg[l + 2:r] + '.*'
    return NO_PYTHON_VERSION


def _available_on_required(json_result, required_plats, required_pys):
    required_tuples = list(itertools.product(required_plats, required_pys))
    name = 'PackageNameNotSet'
    for release in json_result:
        name = release['name']

        def _debug(msg):
            logging.debug(f'{name}: {msg}')

        plat = release['subdir']
        if plat not in required_plats and plat not in NO_ARCH:
            _debug(f'{plat} unknown/not needed')
            continue
        py = _extract_conda_py(release)
        _debug(f'{plat} needs {py}')
        if py in required_pys or py == ANY_PYTHON_VERSION:
            covered_pys = [py] if py != ANY_PYTHON_VERSION else required_pys
            covered_plats = [plat] if plat not in NO_ARCH else required_plats
            to_remove = itertools.product(covered_plats, covered_pys)
            for pair in to_remove:
                try:
                    # combinations can be found multiple times
                    required_tuples.remove(pair)
                except ValueError as e:
                    if 'list.remove' in str(e):
                        continue
                    raise RuntimeError(f'processing {plat} - {py} failed for release: {release}') from e
        if len(required_tuples) == 0:
            _debug('all required tuples found')
            return True

    logging.error(f'{name} not available on {required_tuples}:\n{pformat(json_result)}')
    return False


def _search(pkg):
    """If a result is noarch, we can return early."""
    for plat in REQUIRED_PLATFORMS:
        found_plat, json_list = _search_single(pkg, plat)
        yield json_list
        if found_plat in NO_ARCH:
            return


def _process_inputs(input_paths):
    available = []
    wanted = set(reduce(operator.concat, (_parse_req_file(p) for p in input_paths)))
    for pkg in wanted:
        data = reduce(operator.concat, _search(pkg))
        if _available_on_required(json_result=data,
                                  required_plats=REQUIRED_PLATFORMS,
                                  required_pys=REQUIRED_PYTHONS):
            available.append(pkg)
    for a in available:
        wanted.remove(a)
    return sorted(list(available)), sorted(list(wanted))


def ensure_conda_binary():
    try:
        return check_output(['/usr/bin/env', 'conda', '--version'])
    except CalledProcessError as cs:
        raise RuntimeError('conda not found in PATH') from cs


def main(input_paths: List[Path], output_path: Path = None):
    ensure_conda_binary()
    output_path = output_path or THIS_DIR / 'conda-env.yml'
    available, wanted = _process_inputs(input_paths)
    tpl = jinja2.Template(ENV_TPL)
    with open(output_path, 'wt') as yml:
        yml.write(tpl.render(available=available))
    from rich.console import Console
    from rich.table import Table

    table = Table('available', 'wanted', title='Conda search result')
    for el in itertools.zip_longest(available, wanted, fillvalue=''):
        table.add_row(*el)
    console = Console(record=True)
    console.print(table)
    logging.info(console.export_text())
    console.print(f'Details at {LOGFILE}')


if __name__ == '__main__':
    typer.run(main)
